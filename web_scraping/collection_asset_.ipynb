{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a POST request to the API endpoint\n",
    "# q contains a search query for a specific collection of items.\n",
    "# extracted data and stored in a list called 'all_collections'\n",
    "\n",
    "api_url = 'https://search2.raritysniper.com/multi_search?use_cache=true&x-typesense-api-key=KEY'\n",
    "q ={\n",
    "    \"searches\": [\n",
    "        {\n",
    "            \"query_by\": \"name\",\n",
    "            \"sort_by\": \"launchDate:desc\",\n",
    "            \"highlight_full_fields\": \"name\",\n",
    "            \"collection\": \"collections\",\n",
    "            \"q\": \"*\",\n",
    "            \"facet_by\": \"blockchain,oneDayVolume,supply,thirtyDayVolume,totalVolume,sevenDayVolume,floorPrice\",\n",
    "            \"max_facet_values\": 20,\n",
    "            \"page\": 1,\n",
    "            \"per_page\": 250\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers =  {\"Content-Type\":\"application/json\"}\n",
    "all_collections = []\n",
    "for i in range(1, 10):\n",
    "    q['searches'][0]['page']=i\n",
    "    response = requests.post(api_url, data=json.dumps(q), headers=headers)\n",
    "    r = response.json()\n",
    "    collections = r['results'][0]['hits']\n",
    "    for c in collections:\n",
    "        all_collections.append(c['document'])\n",
    "        # print(c['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from the list of dictionaries\n",
    "\n",
    "collection_df = pd.DataFrame(all_collections)\n",
    "collection_df.to_csv('all_collections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'https://raritysniper.com/' before collection_name in 'collectionSlug' column\n",
    "# add 'assets_' before collection_name in 'collectionSlug' column\n",
    "\n",
    "collection_df['collectionURL'] = 'https://raritysniper.com/' + collection_df['collectionSlug']\n",
    "collection_df['assetsname'] = 'assets_' + collection_df['collectionSlug']\n",
    "collection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fuction get_all_nfts\n",
    "# iterate while function where hits > 0 \n",
    "# create variable nft_keys, where there are only required keys [collectionId, CollectionName, nftId, rarityScore, rank]\n",
    "# payload contains a search query for a specific collection of items.\n",
    "\n",
    "def get_all_nfts(idx, name):\n",
    "    collection_nfts = []\n",
    "    page = 1\n",
    "    payload = {\n",
    "        \"searches\": [\n",
    "            {\n",
    "                \"sort_by\": \"rank:asc,nftId:asc\",\n",
    "                \"collection\": name,\n",
    "                \"q\": \"*\",\n",
    "                \"max_facet_values\": 83,\n",
    "                \"page\": page,\n",
    "                \"per_page\": 250\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    r = requests.post(api_url, json=payload, headers=headers)\n",
    "    while len(r.json()['results'][0]['hits']) > 0:\n",
    "        nfts = r.json()['results'][0]['hits']\n",
    "        for nft in nfts:\n",
    "            nft_key = nft['document']['collectionId'], nft['document']['collectionName'], nft['document']['nftId'], nft['document']['rarityScore'] ,nft['document']['rank']\n",
    "            collection_nfts.append(list(nft_key)) # extract values from dictionaries\n",
    "        print(f'processed: {idx}, collection_name: {name}, page: {page}')\n",
    "        page += 1\n",
    "        payload[\"searches\"][0][\"page\"] = page\n",
    "        r = requests.post(api_url, json=payload, headers=headers)\n",
    "    return collection_nfts\n",
    "\n",
    "\n",
    "# define fucntion dum_csv\n",
    "# create file csv file [collection_assets_batch_1.csv]\n",
    "# take in a list of rows (nfts) and writes them to a CSV file named \"collection_assets_batch_1.csv\".\n",
    "\n",
    "def dump_csv(nfts):\n",
    "    file_exists = os.path.isfile('collection_assets_batch_1.csv')\n",
    "    mode = 'a' if file_exists else 'w'\n",
    "    with open('collection_assets_batch_1.csv', mode, newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if not file_exists: # write headers if file doesn't exist\n",
    "            writer.writerow(['collectionId', 'collectionName', 'nftId', 'rarityScore', 'rank'])\n",
    "        for row in nfts:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# code loops through the first 500 items of the 'assetsname' column in a DataFrame named 'collection_df'.\n",
    "# create a empty list named [all_nft]\n",
    "# returned nfts are appended to a list called all_nfts.\n",
    "\n",
    "all_nfts=[]\n",
    "for idx, asset_name in enumerate(collection_df['assetsname']):\n",
    "    nfts = get_all_nfts(idx, asset_name)\n",
    "    for nft in nfts:\n",
    "        all_nfts.append(nft)\n",
    "    if (idx + 1) % 10 == 0: # After every 10th iteration the dump_csv function is called.\n",
    "        dump_csv(all_nfts) # Passing all_nfts as the argument\n",
    "        all_nfts=[] # all_nfts is reset to an empty list\n",
    "dump_csv(all_nfts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraping-OHQH-_FC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
